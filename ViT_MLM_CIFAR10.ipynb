{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from model import get_train_augmentation_model, get_test_augmentation_model\n",
    "from model import Patches, PatchEncoder, create_encoder, create_decoder, MaskedAutoencoder\n",
    "from model import TrainMonitor, WarmUpCosine\n",
    "\n",
    "# Setting seeds for reproducibility.\n",
    "SEED = 42\n",
    "keras.utils.set_random_seed(SEED)\n",
    "\n",
    "DATASET = \"CIFAR10\"\n",
    "\n",
    "if DATASET == \"CIFAR10\":\n",
    "    from params_CIFAR10 import *\n",
    "if DATASET == \"MNIST\":\n",
    "    from params_MNIST import *\n",
    "\n",
    "\n",
    "model_base_path = Path(MODEL_SAVE_PATH).absolute()\n",
    "now = datetime.now().strftime(\"%Y%m%d_%H-%M-%S\")\n",
    "model_base_path = model_base_path / now\n",
    "if not model_base_path.exists():\n",
    "    model_base_path.mkdir(parents=True)\n",
    "model_filepath = model_base_path / f\"complete_model\"    # the full AE model will be saved\n",
    "checkpoint_path = model_base_path / 'checkpoints' / 'ckpt'   # checkpoints will be saved here\n",
    "weights_path = model_base_path / 'weights' / 'model_weights'   # weights will be saved here\n",
    "train_monitor_progress_path = model_base_path / \"train_progress\"    # path where the training monitor callback images will be saved\n",
    "if not train_monitor_progress_path.exists():\n",
    "    train_monitor_progress_path.mkdir(parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "(x_train, y_train), (x_val, y_val) = (\n",
    "    (x_train[:40000], y_train[:40000]),\n",
    "    (x_train[40000:], y_train[40000:]),\n",
    ")\n",
    "print(f\"Training samples: {len(x_train)}\")\n",
    "print(f\"Validation samples: {len(x_val)}\")\n",
    "print(f\"Testing samples: {len(x_test)}\")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTO)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(x_val)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the image patches:\n",
    "# Get a batch of images.\n",
    "image_batch = next(iter(train_ds))\n",
    "\n",
    "# Augment the images.\n",
    "augmentation_model = get_train_augmentation_model(INPUT_SHAPE, IMAGE_SIZE)\n",
    "augmented_images = augmentation_model(image_batch)\n",
    "\n",
    "# Define the patch layer.\n",
    "patch_layer = Patches(PATCH_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "# Get the patches from the batched images.\n",
    "patches = patch_layer(images=augmented_images)\n",
    "\n",
    "# Now pass the images and the corresponding patches\n",
    "# to the `show_patched_image` method.\n",
    "random_index = patch_layer.show_patched_image(images=augmented_images, patches=patches)\n",
    "\n",
    "# Chose the same image and try reconstructing the patches\n",
    "# into the original image.\n",
    "image = patch_layer.reconstruct_from_patch(patches[random_index])\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulize the masked image:\n",
    "# Create the patch encoder layer.\n",
    "patch_encoder = PatchEncoder(patch_size=PATCH_SIZE, \n",
    "                             projection_dim=ENC_PROJECTION_DIM, \n",
    "                             mask_proportion=MASK_PROPORTION, \n",
    "                             img_channels=IMAGE_CHANNELS)\n",
    "\n",
    "# Get the embeddings and positions.\n",
    "(\n",
    "    unmasked_embeddings,\n",
    "    masked_embeddings,\n",
    "    unmasked_positions,\n",
    "    mask_indices,\n",
    "    unmask_indices,\n",
    ") = patch_encoder(patches=patches)\n",
    "\n",
    "\n",
    "# Show a maksed patch image.\n",
    "new_patch, random_index = patch_encoder.generate_masked_image(patches, unmask_indices)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "img = patch_layer.reconstruct_from_patch(new_patch)\n",
    "plt.imshow(keras.utils.array_to_img(img))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Masked\")\n",
    "plt.subplot(1, 2, 2)\n",
    "img = augmented_images[random_index]\n",
    "plt.imshow(keras.utils.array_to_img(img))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and show the LR scheduler\n",
    "total_steps = int((len(x_train) / BATCH_SIZE) * EPOCHS)\n",
    "warmup_epoch_percentage = 0.15\n",
    "warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
    "scheduled_lrs = WarmUpCosine(\n",
    "    learning_rate_base=LEARNING_RATE,\n",
    "    total_steps=total_steps,\n",
    "    warmup_learning_rate=0.0,\n",
    "    warmup_steps=warmup_steps,\n",
    ")\n",
    "\n",
    "lrs = [scheduled_lrs(step) for step in range(total_steps)]\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Step\", fontsize=14)\n",
    "plt.ylabel(\"LR\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmentation_model = get_train_augmentation_model(INPUT_SHAPE, IMAGE_SIZE)\n",
    "test_augmentation_model = get_test_augmentation_model(IMAGE_SIZE)\n",
    "patch_layer = Patches(PATCH_SIZE, IMAGE_CHANNELS)\n",
    "patch_encoder = PatchEncoder(patch_size=PATCH_SIZE, \n",
    "                             projection_dim=ENC_PROJECTION_DIM, \n",
    "                             mask_proportion=MASK_PROPORTION,\n",
    "                             img_channels=IMAGE_CHANNELS)\n",
    "encoder = create_encoder(num_heads=ENC_NUM_HEADS, num_layers=ENC_LAYERS, \n",
    "                         enc_projection_dim=ENC_PROJECTION_DIM, enc_transformer_units=ENC_TRANSFORMER_UNITS, \n",
    "                         norm_eps=LAYER_NORM_EPS)\n",
    "decoder = create_decoder(num_layers=DEC_LAYERS, num_heads=DEC_NUM_HEADS, image_size=IMAGE_SIZE, img_channels=IMAGE_CHANNELS, num_patches=NUM_PATCHES,\n",
    "                         enc_projection_dim=ENC_PROJECTION_DIM, dec_projection_dim=DEC_PROJECTION_DIM, dec_transformer_units=DEC_TRANSFORMER_UNITS, \n",
    "                         norm_eps=LAYER_NORM_EPS)\n",
    "\n",
    "mae_model = MaskedAutoencoder(\n",
    "    train_augmentation_model=train_augmentation_model,\n",
    "    test_augmentation_model=test_augmentation_model,\n",
    "    patch_layer=patch_layer,\n",
    "    patch_encoder=patch_encoder,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    ")\n",
    "\n",
    "# Assemble the callbacks.\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "# to restore the model from this checkpoint (weights only), use: model.load_weights(checkpoint_path)\n",
    "\n",
    "train_callbacks = [TrainMonitor(next(iter(test_ds)), epoch_interval=5, save_path=train_monitor_progress_path), model_checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=scheduled_lrs, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Compile and pretrain the model.\n",
    "mae_model.compile(\n",
    "    optimizer=optimizer, loss=keras.losses.MeanSquaredError(), metrics=[\"mae\"]\n",
    ")\n",
    "history = mae_model.fit(\n",
    "    train_ds, \n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds, \n",
    "    callbacks=train_callbacks,\n",
    ")\n",
    "\n",
    "# Measure its performance.\n",
    "loss, mae = mae_model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {loss:.2f}\")\n",
    "print(f\"Test MAE: {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke a forward pass to trigger model building and be sure the input dimensions are known to TF and the model can be saved\n",
    "test_img = tf.expand_dims(next(iter(test_ds))[0], axis=0)\n",
    "reconstructed_img = mae_model(test_img)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(keras.utils.array_to_img(reconstructed_img[0, ...]))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final trained model.\n",
    "mae_model.save(model_filepath, save_traces=False)  # This will save the entire model (architecture, weights, optimizer state)\n",
    "# Save model weights only\n",
    "mae_model.save_weights(weights_path)\n",
    "\n",
    "# Load the model.\n",
    "# custom_objects = {\"WarmUpCosine\": WarmUpCosine, \"Patches\": Patches, \"PatchEncoder\": PatchEncoder, \"MaskedAutoencoder\": MaskedAutoencoder} \n",
    "# mae_model = keras.models.load_model(model_filepath, custom_objects=custom_objects)\n",
    "\n",
    "mae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model Loading\n",
    "# Load the model.\n",
    "custom_objects = {\"WarmUpCosine\": WarmUpCosine, \"Patches\": Patches, \"PatchEncoder\": PatchEncoder, \"MaskedAutoencoder\": MaskedAutoencoder} \n",
    "mae_model2 = keras.models.load_model(model_filepath, custom_objects=custom_objects)\n",
    "\n",
    "mae_model2.summary()\n",
    "\n",
    "mae_model3 = MaskedAutoencoder(\n",
    "    train_augmentation_model=train_augmentation_model,\n",
    "    test_augmentation_model=test_augmentation_model,\n",
    "    patch_layer=patch_layer,\n",
    "    patch_encoder=patch_encoder,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    ")\n",
    "mae_model3.build(input_shape=(None, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
    "load_status = mae_model3.load_weights(weights_path)\n",
    "# `assert_consumed` can be used as validation that all variable values have been\n",
    "# restored from the checkpoint. See `tf.train.Checkpoint.restore` for other\n",
    "# methods in the Status object.\n",
    "# load_status.assert_consumed()\n",
    "mae_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "reconstructed_img = mae_model(test_img)\n",
    "ax[0].imshow(keras.utils.array_to_img(reconstructed_img[0, ...]))\n",
    "ax[0].axis(\"off\")\n",
    "reconstructed_img2 = mae_model2(test_img)\n",
    "# plt.figure(figsize=(4, 4))\n",
    "ax[1].imshow(keras.utils.array_to_img(reconstructed_img2[0, ...]))\n",
    "ax[1].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting and using the ViT Encoder for linear probing \n",
    "#### (i.e. adding a classification layer to the encoder stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the augmentation layers.\n",
    "train_augmentation_model = mae_model.train_augmentation_model\n",
    "test_augmentation_model = mae_model.test_augmentation_model\n",
    "\n",
    "# Extract the patchers.\n",
    "patch_layer = mae_model.patch_layer\n",
    "patch_encoder = mae_model.patch_encoder\n",
    "patch_encoder.downstream = True  # Swtich the downstream flag to True.\n",
    "\n",
    "# Extract the encoder.\n",
    "encoder = mae_model.encoder\n",
    "\n",
    "# Pack as a model.\n",
    "downstream_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)),     # or just INPUT_SHAPE\n",
    "        patch_layer,\n",
    "        patch_encoder,\n",
    "        encoder,\n",
    "        layers.BatchNormalization(),  # Refer to A.1 (Linear probing).\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=\"linear_probe_model\",\n",
    ")\n",
    "\n",
    "# Only the final classification layer of the `downstream_model` should be trainable.\n",
    "for layer in downstream_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "downstream_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets for linear probing\n",
    "def prepare_data(images, labels, is_train=True):\n",
    "    if is_train:\n",
    "        augmentation_model = train_augmentation_model\n",
    "    else:\n",
    "        augmentation_model = test_augmentation_model\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE).map(\n",
    "        lambda x, y: (augmentation_model(x), y), num_parallel_calls=AUTO\n",
    "    )\n",
    "    return dataset.prefetch(AUTO)\n",
    "\n",
    "\n",
    "train_ds = prepare_data(x_train, y_train)\n",
    "val_ds = prepare_data(x_train, y_train, is_train=False)\n",
    "test_ds = prepare_data(x_test, y_test, is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linear probing\n",
    "\n",
    "linear_probe_epochs = 50\n",
    "linear_prob_lr = 0.1\n",
    "warm_epoch_percentage = 0.1\n",
    "steps = int((len(x_train) // BATCH_SIZE) * linear_probe_epochs)\n",
    "\n",
    "warmup_steps = int(steps * warm_epoch_percentage)\n",
    "scheduled_lrs = WarmUpCosine(\n",
    "    learning_rate_base=linear_prob_lr,\n",
    "    total_steps=steps,\n",
    "    warmup_learning_rate=0.0,\n",
    "    warmup_steps=warmup_steps,\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=scheduled_lrs, momentum=0.9)\n",
    "downstream_model.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "downstream_model.fit(train_ds, validation_data=val_ds, epochs=linear_probe_epochs)\n",
    "\n",
    "loss, accuracy = downstream_model.evaluate(test_ds)\n",
    "accuracy = round(accuracy * 100, 2)\n",
    "print(f\"Accuracy on the test set: {accuracy}%.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting and using the ViT Encoder as stand alone preprocessor for further classificators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the augmentation layers.\n",
    "train_augmentation_model = mae_model.train_augmentation_model\n",
    "test_augmentation_model = mae_model.test_augmentation_model\n",
    "\n",
    "# Extract the patchers.\n",
    "patch_layer = mae_model.patch_layer\n",
    "patch_encoder = mae_model.patch_encoder\n",
    "patch_encoder.downstream = True  # Switch the downstream flag to True.\n",
    "\n",
    "# Extract the encoder.\n",
    "encoder = mae_model.encoder\n",
    "\n",
    "# Pack as a model.\n",
    "vit_encoder = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)),     # or just INPUT_SHAPE\n",
    "        patch_layer,\n",
    "        patch_encoder,\n",
    "        encoder,\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "    ],\n",
    "    name=\"vit_encoder\",\n",
    ")\n",
    "\n",
    "# The encoder should not be trainable\n",
    "for layer in vit_encoder.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# post-train the vit_encoder batchnorm layer\n",
    "# vit_encoder.compile(\n",
    "#     optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "# )\n",
    "# vit_encoder.fit(train_ds, validation_data=val_ds, epochs=5)\n",
    "\n",
    "vit_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "def prepare_data(images, labels, is_vit_train=False):   #normaly there is no casewhere we wan to retrain the encoder here\n",
    "    if is_vit_train:\n",
    "        augmentation_model = train_augmentation_model\n",
    "    else:\n",
    "        augmentation_model = test_augmentation_model\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if is_vit_train:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE).map(\n",
    "        lambda x, y: (augmentation_model(x), y), num_parallel_calls=AUTO\n",
    "    )\n",
    "    return dataset.prefetch(AUTO)\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "# (x_train, y_train), (x_val, y_val) = (\n",
    "#     (x_train[:40000], y_train[:40000]),\n",
    "#     (x_train[40000:], y_train[40000:]),\n",
    "# )\n",
    "train_ds = prepare_data(x_train, y_train)\n",
    "val_ds = prepare_data(x_val, y_val)\n",
    "test_ds = prepare_data(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a sklearn SVM classifier on the features extracted from the encoder\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train_features = vit_encoder.predict(x_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit_encoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
